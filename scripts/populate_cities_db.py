#!/usr/bin/env python3
"""
V√°ros-adatb√°zis gener√°tor - Multi-city analytics t√°mogat√°s (PROFESSZION√ÅLIS JAV√çTOTT VERZI√ì)
Global Weather Analyzer projekt

F√°jl: scripts/populate_cities_db.py
C√©l: SQLite adatb√°zis gener√°l√°sa 3 forr√°sb√≥l:
- SimpleMaps worldcities.csv (100k+ v√°ros)
- Meteostat API (meteorol√≥giai √°llom√°sok)  
- HungaroMet priorit√°s (magyar adatmin≈ës√©g)

KRITIKUS JAV√çT√ÅSOK:
‚úÖ None-safe inventory feldolgoz√°s (TypeError: None >= '2023-01-01' megoldva)
‚úÖ Robusztus data_quality_score sz√°m√≠t√°s
‚úÖ Professional error handling minden met√≥dusn√°l
‚úÖ Type hints teljes lefedetts√©g
‚úÖ Comprehensive logging √©s hibakeres√©s
‚úÖ Defensive programming elvek alkalmaz√°sa

Verzi√≥: v2.1.0 - Production Ready
"""

import sys
import os
import sqlite3
import pandas as pd
import logging
import time
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple, Union
from datetime import datetime
from dataclasses import dataclass
import json
from geopy.distance import geodesic
from dotenv import load_dotenv

# Projektgy√∂k√©r hozz√°ad√°sa a Python path-hoz
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data.meteostat_client import MeteostatClient, MeteostatStation, MeteostatAPIError

# Logging inicializ√°l√°s - JAV√çTOTT verzi√≥ (k√∂nyvt√°r el≈ëbb l√©trehozva)
# Logs k√∂nyvt√°r l√©trehoz√°sa ELS≈ê L√âP√âSK√âNT
Path("logs").mkdir(exist_ok=True)

# Professional logging be√°ll√≠t√°s
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/populate_cities_db.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class CityRecord:
    """
    V√°ros adatstrukt√∫ra adatb√°zis t√°rol√°shoz
    
    Professional data model a tiszta architekt√∫r√°hoz
    """
    city: str
    lat: float
    lon: float
    country: str
    country_code: str
    population: Optional[int] = None
    continent: Optional[str] = None
    admin_name: Optional[str] = None
    capital: Optional[str] = None
    timezone: Optional[str] = None
    
    # Meteostat integr√°ci√≥
    meteostat_station_id: Optional[str] = None
    meteostat_station_name: Optional[str] = None
    station_elevation: Optional[float] = None
    station_distance: Optional[float] = None
    station_inventory: Optional[str] = None
    
    # HungaroMet priorit√°s
    hungaromet_priority: Optional[int] = None
    data_quality_score: Optional[int] = None
    last_data_update: Optional[str] = None


class CityDatabasePopulator:
    """
    V√°ros-adatb√°zis gener√°tor oszt√°ly
    
    PROFESSZION√ÅLIS IMPLEMENT√ÅCI√ì:
    - SOLID elvek alkalmaz√°sa
    - Comprehensive error handling  
    - None-safe adatfeldolgoz√°s
    - Type safety minden met√≥dusn√°l
    - Professional logging
    - Defensive programming
    
    Felel≈ëss√©gek:
    - SimpleMaps CSV feldolgoz√°sa √©s valid√°l√°sa
    - Meteostat API integr√°ci√≥ hibakezel√©ssel
    - HungaroMet priorit√°s alkalmaz√°sa
    - SQLite adatb√°zis gener√°l√°sa indexekkel
    - Progress tracking √©s r√©szletes hibakezel√©s
    """
    
    # HungaroMet priorit√°si rendszer - Dunai Hidrol√≥giai Inform√°ci√≥s Rendszer alapj√°n
    HUNGARIAN_PRIORITY_CITIES: Dict[str, Dict[str, Union[str, int]]] = {
        # PRIORIT√ÅS 1: Kritikus √°llom√°sok
        "Budapest": {"station_type": "auto", "priority": 1, "special": "capital"},
        "Debrecen": {"station_type": "auto", "priority": 1, "special": "major_city"},
        "Szeged": {"station_type": "auto", "priority": 1, "special": "major_city"},
        "Miskolc": {"station_type": "auto", "priority": 1, "special": "major_city"},
        "B√©k√©scsaba": {"station_type": "auto", "priority": 1, "special": "regional"},
        "Eger": {"station_type": "auto", "priority": 1, "special": "historical"},
        "Nagykanizsa": {"station_type": "auto", "priority": 1, "special": "regional"},
        "Paks": {"station_type": "auto", "priority": 1, "special": "nuclear_plant"},
        "Si√≥fok": {"station_type": "auto", "priority": 1, "special": "balaton"},
        "Sopron": {"station_type": "auto", "priority": 1, "special": "border"},
        "Szombathely": {"station_type": "auto", "priority": 1, "special": "western"},
        
        # PRIORIT√ÅS 2: Fontos region√°lis k√∂zpontok
        "P√©cs": {"station_type": "auto", "priority": 2, "special": "major_city"},
        "Gy≈ër": {"station_type": "auto", "priority": 2, "special": "major_city"},
        "Ny√≠regyh√°za": {"station_type": "auto", "priority": 2, "special": "eastern"},
        "Kecskem√©t": {"station_type": "auto", "priority": 2, "special": "central"},
        "Sz√©kesfeh√©rv√°r": {"station_type": "auto", "priority": 2, "special": "central"},
        "Szolnok": {"station_type": "auto", "priority": 2, "special": "central"},
        "Tatab√°nya": {"station_type": "auto", "priority": 2, "special": "industrial"},
        "Kaposv√°r": {"station_type": "auto", "priority": 2, "special": "southern"},
        "Veszpr√©m": {"station_type": "auto", "priority": 2, "special": "central"},
        "Zalaegerszeg": {"station_type": "auto", "priority": 2, "special": "western"},
        
        # PRIORIT√ÅS 1+: Speci√°lis meteorol√≥giai √°llom√°sok
        "K√©kestet≈ë": {"station_type": "auto", "priority": 1, "special": "highest_point"},
        "Hegyh√°ts√°l": {"station_type": "auto", "priority": 1, "special": "climate_station"},
        "Martonv√°s√°r": {"station_type": "auto", "priority": 1, "special": "agricultural"},
        
        # PRIORIT√ÅS 2: Rep√ºl≈ët√©ri √©s turisztikai √°llom√°sok
        "Ferihegy": {"station_type": "auto", "priority": 2, "special": "airport"},
        "Balaton": {"station_type": "auto", "priority": 2, "special": "lake_region"}
    }
    
    def __init__(self, csv_path: str, db_path: str, meteostat_api_key: str) -> None:
        """
        Inicializ√°l√°s teljes valid√°ci√≥val
        
        Args:
            csv_path: SimpleMaps worldcities.csv f√°jl el√©r√©si √∫tja
            db_path: C√©l SQLite adatb√°zis el√©r√©si √∫tja
            meteostat_api_key: Meteostat API kulcs
            
        Raises:
            ValueError: Invalid param√©terek eset√©n
            FileNotFoundError: CSV f√°jl nem tal√°lhat√≥
        """
        self.csv_path = Path(csv_path)
        self.db_path = Path(db_path)
        self.meteostat_api_key = meteostat_api_key
        
        # Input valid√°ci√≥
        if not self.meteostat_api_key or len(self.meteostat_api_key) < 10:
            raise ValueError("√ârv√©nytelen Meteostat API kulcs")
        
        # Meteostat client inicializ√°l√°sa hibakezel√©ssel
        try:
            self.meteostat = MeteostatClient(meteostat_api_key)
        except Exception as e:
            logger.error(f"Meteostat client inicializ√°l√°si hiba: {e}")
            raise
        
        # Statisztik√°k k√∂vet√©se
        self.stats: Dict[str, Union[int, float]] = {
            'total_cities': 0,
            'hungarian_cities': 0,
            'cities_with_stations': 0,
            'meteostat_requests': 0,
            'processing_time': 0.0,
            'api_errors': 0,
            'validation_errors': 0
        }
        
        logger.info("üöÄ CityDatabasePopulator inicializ√°lva (Professional v2.1.0)")
        logger.info(f"üìÅ CSV f√°jl: {self.csv_path}")
        logger.info(f"üóÑÔ∏è Adatb√°zis: {self.db_path}")
        logger.info(f"üîë API kulcs hossza: {len(self.meteostat_api_key)} karakter")
    
    def create_database_schema(self) -> None:
        """
        SQLite adatb√°zis l√©trehoz√°sa optimaliz√°lt s√©m√°val √©s indexekkel
        
        Professional database design:
        - Normalized structure
        - Performance indexes
        - Constraint validation
        - Metadata tracking
        
        Raises:
            sqlite3.Error: Adatb√°zis m≈±veleti hib√°k
        """
        logger.info("üèóÔ∏è Adatb√°zis s√©ma l√©trehoz√°sa...")
        
        try:
            # Sz√ºl≈ë k√∂nyvt√°r l√©trehoz√°sa ha nem l√©tezik
            self.db_path.parent.mkdir(parents=True, exist_ok=True)
            
            # R√©gi adatb√°zis safe t√∂rl√©se
            if self.db_path.exists():
                backup_path = self.db_path.with_suffix(f'.backup_{int(time.time())}.db')
                self.db_path.rename(backup_path)
                logger.info(f"üì¶ R√©gi adatb√°zis archiv√°lva: {backup_path}")
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # F≈ë cities t√°bla optimaliz√°lt s√©m√°val
                cursor.execute('''
                    CREATE TABLE cities (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        city TEXT NOT NULL,
                        lat REAL NOT NULL CHECK(lat >= -90 AND lat <= 90),
                        lon REAL NOT NULL CHECK(lon >= -180 AND lon <= 180),
                        country TEXT NOT NULL,
                        country_code TEXT NOT NULL CHECK(LENGTH(country_code) = 2),
                        population INTEGER CHECK(population >= 0),
                        continent TEXT,
                        admin_name TEXT,
                        capital TEXT,
                        timezone TEXT,
                        
                        -- Meteostat integr√°ci√≥ metaadatok
                        meteostat_station_id TEXT,
                        meteostat_station_name TEXT,
                        station_elevation REAL,
                        station_distance REAL CHECK(station_distance >= 0),
                        station_inventory TEXT,
                        
                        -- HungaroMet priorit√°s √©s min≈ës√©g
                        hungaromet_priority INTEGER CHECK(hungaromet_priority BETWEEN 1 AND 5),
                        data_quality_score INTEGER CHECK(data_quality_score BETWEEN 1 AND 10),
                        last_data_update DATE,
                        
                        -- Audit trail
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        
                        -- Constraints
                        UNIQUE(city, country_code, lat, lon)
                    )
                ''')
                
                # Performance indexek l√©trehoz√°sa
                performance_indexes = [
                    "CREATE INDEX idx_country_code ON cities (country_code)",
                    "CREATE INDEX idx_population_desc ON cities (population DESC) WHERE population IS NOT NULL",
                    "CREATE INDEX idx_data_quality_country ON cities (country_code, data_quality_score DESC) WHERE data_quality_score IS NOT NULL",
                    "CREATE INDEX idx_meteostat_stations ON cities (meteostat_station_id) WHERE meteostat_station_id IS NOT NULL",
                    "CREATE INDEX idx_coordinates ON cities (lat, lon)",
                    "CREATE INDEX idx_hungaromet_priority ON cities (country_code, hungaromet_priority) WHERE hungaromet_priority IS NOT NULL",
                    "CREATE INDEX idx_station_distance ON cities (station_distance) WHERE station_distance IS NOT NULL",
                    "CREATE INDEX idx_continent_population ON cities (continent, population DESC) WHERE continent IS NOT NULL AND population IS NOT NULL",
                    "CREATE INDEX idx_city_name_search ON cities (city COLLATE NOCASE)",
                    "CREATE INDEX idx_updated_at ON cities (updated_at DESC)"
                ]
                
                for index_sql in performance_indexes:
                    cursor.execute(index_sql)
                    logger.debug(f"‚úÖ Index l√©trehozva: {index_sql.split()[2]}")
                
                # Metaadat t√°bla audit trail-lel
                cursor.execute('''
                    CREATE TABLE generation_metadata (
                        id INTEGER PRIMARY KEY,
                        generation_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        csv_file_path TEXT NOT NULL,
                        total_cities INTEGER NOT NULL,
                        hungarian_cities INTEGER NOT NULL,
                        cities_with_stations INTEGER NOT NULL,
                        meteostat_requests INTEGER NOT NULL,
                        api_errors INTEGER DEFAULT 0,
                        validation_errors INTEGER DEFAULT 0,
                        processing_time_seconds REAL NOT NULL,
                        meteostat_api_key_hash TEXT NOT NULL,
                        version TEXT DEFAULT '2.1.0'
                    )
                ''')
                
                # Error log t√°bla hibakeres√©shez
                cursor.execute('''
                    CREATE TABLE processing_errors (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        city_name TEXT,
                        error_type TEXT NOT NULL,
                        error_message TEXT NOT NULL,
                        processing_step TEXT
                    )
                ''')
                
                conn.commit()
                logger.info("‚úÖ Adatb√°zis s√©ma sikeresen l√©trehozva (optimaliz√°lt indexekkel)")
                
        except sqlite3.Error as e:
            logger.error(f"‚ùå Adatb√°zis s√©ma l√©trehoz√°si hiba: {e}")
            raise
        except Exception as e:
            logger.error(f"‚ùå V√°ratlan hiba adatb√°zis l√©trehoz√°skor: {e}")
            raise
    
    def load_simplemaps_data(self) -> pd.DataFrame:
        """
        SimpleMaps worldcities.csv bet√∂lt√©se √©s professzion√°lis el≈ëfeldolgoz√°sa
        
        Professional data validation:
        - Schema validation
        - Data type conversion
        - Null handling
        - Coordinate validation
        - Duplicate detection
        
        Returns:
            Valid√°lt √©s tiszt√≠tott Pandas DataFrame
            
        Raises:
            FileNotFoundError: CSV f√°jl nem tal√°lhat√≥
            ValueError: Invalid CSV strukt√∫ra
            pd.errors.ParserError: CSV parsing hib√°k
        """
        logger.info("üìä SimpleMaps CSV bet√∂lt√©se √©s valid√°l√°sa...")
        
        if not self.csv_path.exists():
            raise FileNotFoundError(f"SimpleMaps CSV nem tal√°lhat√≥: {self.csv_path}")
        
        try:
            # CSV bet√∂lt√©se robusztus parserol√°ssal
            df = pd.read_csv(
                self.csv_path,
                encoding='utf-8',
                low_memory=False,
                na_values=['', 'NULL', 'null', 'N/A', 'n/a', '#N/A'],
                keep_default_na=True
            )
            logger.info(f"üìà CSV sikeresen bet√∂ltve: {len(df):,} rekord")
            
            # Oszlopok standardiz√°l√°sa
            df.columns = df.columns.str.lower().str.strip()
            
            # Sz√ºks√©ges oszlopok valid√°l√°sa
            required_columns = ['city', 'lat', 'lng', 'country', 'iso2']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                raise ValueError(f"Hi√°nyz√≥ k√∂telez≈ë oszlopok: {missing_columns}")
            
            # Oszlopnevek normaliz√°l√°sa
            column_mapping = {
                'lng': 'lon',
                'iso2': 'country_code',
                'admin_name': 'admin_name',
                'capital': 'capital',
                'population': 'population'
            }
            
            df = df.rename(columns=column_mapping)
            logger.info("‚úÖ Oszlopnevek normaliz√°lva")
            
            # Kritikus mez≈ëk null check
            critical_nulls = df[['city', 'lat', 'lon', 'country', 'country_code']].isnull().sum()
            if critical_nulls.any():
                logger.warning(f"‚ö†Ô∏è Hi√°nyz√≥ kritikus adatok: {critical_nulls[critical_nulls > 0].to_dict()}")
            
            # Adattiszt√≠t√°s √©s valid√°l√°s
            df = self._clean_and_validate_data(df)
            
            # Duplik√°tumok kezel√©se
            original_count = len(df)
            df = df.drop_duplicates(subset=['city', 'country_code', 'lat', 'lon'], keep='first')
            duplicates_removed = original_count - len(df)
            
            if duplicates_removed > 0:
                logger.info(f"üîÑ Duplik√°tumok elt√°vol√≠tva: {duplicates_removed}")
            
            self.stats['total_cities'] = len(df)
            logger.info(f"‚úÖ SimpleMaps adatok sikeresen feldolgozva: {len(df):,} √©rv√©nyes rekord")
            
            return df
            
        except pd.errors.ParserError as e:
            logger.error(f"‚ùå CSV parsing hiba: {e}")
            self.stats['validation_errors'] += 1
            raise
        except Exception as e:
            logger.error(f"‚ùå SimpleMaps bet√∂lt√©si hiba: {e}")
            self.stats['validation_errors'] += 1
            raise
    
    def _clean_and_validate_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Adattiszt√≠t√°s √©s valid√°l√°s professzion√°lis v√©grehajt√°sa
        
        Args:
            df: Nyers DataFrame
            
        Returns:
            Tiszt√≠tott √©s valid√°lt DataFrame
        """
        logger.info("üßπ Adattiszt√≠t√°s √©s valid√°l√°s...")
        
        original_count = len(df)
        
        # String mez≈ëk tiszt√≠t√°sa
        string_columns = ['city', 'country', 'country_code', 'admin_name', 'capital']
        for col in string_columns:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip()
                df[col] = df[col].replace('nan', pd.NA)
        
        # K√∂telez≈ë mez≈ëk null √©rt√©keinek elt√°vol√≠t√°sa
        df = df.dropna(subset=['city', 'lat', 'lon', 'country', 'country_code'])
        
        # Country code standardiz√°l√°sa
        df['country_code'] = df['country_code'].str.upper()
        df = df[df['country_code'].str.len() == 2]  # Csak ISO-2 k√≥dok
        
        # Koordin√°t√°k valid√°l√°sa
        coordinate_mask = (
            (df['lat'] >= -90) & (df['lat'] <= 90) &
            (df['lon'] >= -180) & (df['lon'] <= 180) &
            (df['lat'] != 0) & (df['lon'] != 0)  # Null Island kiz√°r√°sa
        )
        df = df[coordinate_mask]
        
        # Popul√°ci√≥ tiszt√≠t√°sa
        if 'population' in df.columns:
            df['population'] = pd.to_numeric(df['population'], errors='coerce')
            df['population'] = df['population'].where(df['population'] > 0)
        
        # V√°ros n√©vvalid√°ci√≥
        df = df[df['city'].str.len() >= 2]  # Min 2 karakter
        df = df[~df['city'].str.contains(r'^\d+$', regex=True, na=False)]  # Nem csak sz√°mok
        
        invalid_count = original_count - len(df)
        if invalid_count > 0:
            logger.warning(f"‚ö†Ô∏è √ârv√©nytelen rekordok elt√°vol√≠tva: {invalid_count}")
            self.stats['validation_errors'] += invalid_count
        
        logger.info(f"‚úÖ Adattiszt√≠t√°s befejezve: {len(df):,} √©rv√©nyes rekord")
        return df
    
    def enhance_hungarian_cities(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Magyar v√°rosok Meteostat √°llom√°sokkal val√≥ kieg√©sz√≠t√©se
        JAV√çTOTT None-safe implement√°ci√≥val
        
        Args:
            df: Cities DataFrame
            
        Returns:
            Kieg√©sz√≠tett DataFrame Meteostat √°llom√°sadatokkal
            
        Raises:
            MeteostatAPIError: API kommunik√°ci√≥s hib√°k eset√©n
        """
        logger.info("üá≠üá∫ Magyar v√°rosok Meteostat √°llom√°sokkal val√≥ kieg√©sz√≠t√©se...")
        
        hungarian_cities = df[df['country_code'] == 'HU'].copy()
        self.stats['hungarian_cities'] = len(hungarian_cities)
        
        if len(hungarian_cities) == 0:
            logger.warning("‚ö†Ô∏è Nincsenek magyar v√°rosok a CSV-ben")
            return df
        
        logger.info(f"üìä Feldolgozand√≥ magyar v√°rosok: {len(hungarian_cities)}")
        
        enhanced_count = 0
        error_count = 0
        
        for idx, city in hungarian_cities.iterrows():
            city_name = city['city']
            
            try:
                logger.info(f"üîç Feldolgoz√°s: {city_name} ({enhanced_count + 1}/{len(hungarian_cities)})")
                
                # JAV√çT√ÅS: Meteostat k√∂zeli √°llom√°sok lek√©rdez√©se HELYES radius param√©terrel
                # Radius M√âTERBEN van! 50 km = 50000 m√©ter
                nearby_stations = self.meteostat.get_nearby_stations(
                    city['lat'], city['lon'], limit=5, radius=50000  # 50 km = 50000 m√©ter
                )
                self.stats['meteostat_requests'] += 1
                
                if nearby_stations and len(nearby_stations) > 0:
                    logger.info(f"  ‚úÖ Tal√°lat: {len(nearby_stations)} k√∂zeli √°llom√°s")
                    
                    # Legjobb √°llom√°s kiv√°laszt√°sa
                    best_station = self._select_best_station(nearby_stations, city.to_dict())
                    
                    if best_station:
                        logger.info(f"  üéØ Legjobb √°llom√°s: {best_station.name} ({best_station.distance:.1f} km)")
                        
                        # √Ållom√°s metaadatok lek√©rdez√©se
                        station_meta = self.meteostat.get_station_meta(best_station.id)
                        self.stats['meteostat_requests'] += 1
                        
                        if station_meta:
                            # DataFrame friss√≠t√©se safe m√≥don
                            df.at[idx, 'meteostat_station_id'] = station_meta.id
                            df.at[idx, 'meteostat_station_name'] = station_meta.name
                            df.at[idx, 'station_elevation'] = station_meta.elevation
                            df.at[idx, 'station_distance'] = best_station.distance
                            
                            # Inventory JSON form√°tumban safe m√≥don
                            if station_meta.inventory:
                                try:
                                    inventory_json = json.dumps(station_meta.inventory)
                                    df.at[idx, 'station_inventory'] = inventory_json
                                except (TypeError, ValueError) as e:
                                    logger.warning(f"  ‚ö†Ô∏è Inventory serialization hiba: {e}")
                            
                            # HungaroMet priorit√°s hozz√°ad√°sa
                            hungaromet_data = self.HUNGARIAN_PRIORITY_CITIES.get(city_name, {})
                            df.at[idx, 'hungaromet_priority'] = hungaromet_data.get('priority', 3)
                            
                            # JAV√çTOTT Adatmin≈ës√©g pontsz√°m sz√°m√≠t√°sa None-safe m√≥don
                            df.at[idx, 'data_quality_score'] = self._calculate_quality_score_safe(
                                station_meta, hungaromet_data, best_station.distance
                            )
                            
                            # Utols√≥ friss√≠t√©s timestamp
                            df.at[idx, 'last_data_update'] = datetime.now().strftime('%Y-%m-%d')
                            
                            enhanced_count += 1
                            self.stats['cities_with_stations'] += 1
                            
                            logger.info(f"  ‚úÖ √Ållom√°s sikeresen p√°ros√≠tva: {station_meta.name} ({best_station.distance:.1f} km)")
                        else:
                            logger.warning(f"  ‚ùå √Ållom√°s metaadatok nem el√©rhet≈ëk: {best_station.id}")
                            error_count += 1
                    else:
                        logger.warning(f"  ‚ùå Nincs megfelel≈ë √°llom√°s 50 km-es k√∂rzetben")
                        error_count += 1
                else:
                    logger.warning(f"  ‚ùå Nincs k√∂zeli √°llom√°s 50 km-es k√∂rzetben")
                    error_count += 1
                
                # Professional rate limiting (500 k√©r√©s/h√≥nap limit)
                time.sleep(0.2)  # Max 5 k√©r√©s/sec
                
            except MeteostatAPIError as e:
                logger.error(f"‚ùå Meteostat API hiba {city_name}-n√©l: {e}")
                self._log_processing_error(city_name, "MeteostatAPIError", str(e), "station_lookup")
                self.stats['api_errors'] += 1
                error_count += 1
                continue
            except Exception as e:
                logger.error(f"‚ùå V√°ratlan hiba {city_name}-n√©l: {e}")
                self._log_processing_error(city_name, "UnexpectedError", str(e), "city_enhancement")
                error_count += 1
                continue
        
        success_rate = (enhanced_count / len(hungarian_cities)) * 100 if len(hungarian_cities) > 0 else 0
        
        logger.info("=" * 60)
        logger.info("üá≠üá∫ MAGYAR V√ÅROSOK KIEG√âSZ√çT√âS BEFEJEZVE")
        logger.info("=" * 60)
        logger.info(f"‚úÖ Sikeresen kieg√©sz√≠tett v√°rosok: {enhanced_count}/{len(hungarian_cities)} ({success_rate:.1f}%)")
        logger.info(f"‚ùå Hib√°s v√°rosok: {error_count}")
        logger.info(f"üîó Meteostat API k√©r√©sek: {self.stats['meteostat_requests']}")
        logger.info(f"‚ö†Ô∏è API hib√°k: {self.stats['api_errors']}")
        logger.info("=" * 60)
        
        return df
    
    def _select_best_station(self, stations: List[MeteostatStation], city: Dict[str, Any]) -> Optional[MeteostatStation]:
        """
        Legjobb meteorol√≥giai √°llom√°s kiv√°laszt√°sa v√°roshoz
        Professional scoring algorithmusal
        
        Args:
            stations: K√∂zeli √°llom√°sok list√°ja
            city: V√°ros adatai
            
        Returns:
            Legjobb √°llom√°s vagy None ha nincs megfelel≈ë
        """
        if not stations or len(stations) == 0:
            return None
        
        best_station = None
        best_score = -1.0
        
        logger.debug(f"  üîç √Ållom√°s √©rt√©kel√©s: {len(stations)} kandid√°tus")
        
        for station in stations:
            try:
                # T√°vols√°g valid√°l√°s
                if not station.distance or station.distance > 50:  # Max 50 km
                    logger.debug(f"    ‚ùå T√∫l t√°voli √°llom√°s: {station.name} ({station.distance} km)")
                    continue
                
                # Pontsz√°m sz√°m√≠t√°sa
                score = self._calculate_station_score(station, city)
                
                logger.debug(f"    üìä {station.name}: {score:.2f} pont ({station.distance:.1f} km)")
                
                if score > best_score:
                    best_score = score
                    best_station = station
                    
            except Exception as e:
                logger.warning(f"    ‚ö†Ô∏è √Ållom√°s √©rt√©kel√©si hiba {station.name}: {e}")
                continue
        
        if best_station:
            logger.debug(f"  üèÜ Gy≈ëztes √°llom√°s: {best_station.name} ({best_score:.2f} pont)")
        
        return best_station
    
    def _calculate_station_score(self, station: MeteostatStation, city: Dict[str, Any]) -> float:
        """
        √Ållom√°s pontsz√°m sz√°m√≠t√°sa professzion√°lis krit√©riumokkal
        
        Args:
            station: Meteostat √°llom√°s
            city: V√°ros adatai
            
        Returns:
            Pontsz√°m (0-10 sk√°la)
        """
        score = 5.0  # alap√©rtelmezett k√∂z√©p√©rt√©k
        
        try:
            # T√°vols√°g pontsz√°m (min√©l k√∂zelebb, ann√°l jobb)
            if station.distance is not None:
                if station.distance <= 5:
                    score += 3.0  # Nagyon k√∂zeli
                elif station.distance <= 15:
                    score += 2.0  # K√∂zeli
                elif station.distance <= 30:
                    score += 1.0  # Elfogadhat√≥
                else:
                    score -= 1.0  # T√°voli
            
            # Inventory alap√∫ adatmin≈ës√©g b√≥nusz
            if hasattr(station, 'inventory') and station.inventory:
                inventory = station.inventory
                
                # Daily data b√≥nusz - JAV√çTOTT None-safe check
                daily_data = self._safe_inventory_check(inventory, 'daily', 'end')
                if daily_data and isinstance(daily_data, str) and daily_data >= '2020-01-01':
                    score += 2.0
                elif daily_data and isinstance(daily_data, str) and daily_data >= '2015-01-01':
                    score += 1.0
                
                # Hourly data b√≥nusz
                hourly_data = self._safe_inventory_check(inventory, 'hourly', 'end')
                if hourly_data and isinstance(hourly_data, str) and hourly_data >= '2020-01-01':
                    score += 1.0
            
            # Orsz√°g egyez√©s b√≥nusz
            if hasattr(station, 'country') and station.country == "HU":
                score += 2.0
            
            # N√©v hasonl√≥s√°g b√≥nusz
            city_name = city.get('city', '').lower()
            station_name = getattr(station, 'name', '').lower()
            if city_name and station_name and city_name in station_name:
                score += 1.0
            
            # Elevation inform√°ci√≥ b√≥nusz
            if hasattr(station, 'elevation') and station.elevation is not None:
                score += 0.5
                
        except Exception as e:
            logger.warning(f"√Ållom√°s pontsz√°m sz√°m√≠t√°si hiba: {e}")
            score = 3.0  # Fallback score
        
        return max(0.0, min(10.0, score))
    
    def _safe_inventory_check(self, inventory: Optional[Dict[str, Any]], section: str, field: str) -> Optional[str]:
        """
        KRITIKUS JAV√çT√ÅS: None-safe inventory field extraction
        
        Ez a met√≥dus megoldja a TypeError: None >= '2023-01-01' hib√°t!
        
        Args:
            inventory: Inventory dict (lehet None)
            section: Inventory szekci√≥ ('daily', 'hourly', stb.)
            field: Mez≈ë n√©v ('start', 'end', stb.)
            
        Returns:
            Field √©rt√©k vagy None ha nem l√©tezik/√©rv√©nytelen
        """
        try:
            if not inventory or not isinstance(inventory, dict):
                return None
                
            section_data = inventory.get(section)
            if not section_data or not isinstance(section_data, dict):
                return None
                
            field_value = section_data.get(field)
            
            # KRITIKUS: None check √©s type validation
            if field_value is None:
                return None
                
            # String t√≠pus biztos√≠t√°sa
            if isinstance(field_value, str) and len(field_value) >= 10:  # YYYY-MM-DD format
                return field_value
                
            return None
            
        except (AttributeError, TypeError, KeyError) as e:
            logger.debug(f"Safe inventory check hiba: {e}")
            return None
    
    def _calculate_quality_score_safe(self, station: MeteostatStation, hungaromet_data: Dict[str, Any], distance: float) -> int:
        """
        KRITIKUSAN JAV√çTOTT Adatmin≈ës√©g pontsz√°m sz√°m√≠t√°sa 1-10 sk√°l√°n.
        Teljesen None-safe implement√°ci√≥ a TypeError elker√ºl√©s√©re.
        
        Args:
            station: Meteostat √°llom√°s
            hungaromet_data: HungaroMet priorit√°s adatok
            distance: T√°vols√°g km-ben
            
        Returns:
            Adatmin≈ës√©g pontsz√°m (1-10)
        """
        try:
            score = 5  # alap√©rtelmezett k√∂z√©p√©rt√©k
            
            # HungaroMet priorit√°s b√≥nusz
            priority = hungaromet_data.get('priority', 3)
            if priority == 1:
                score += 3
            elif priority == 2:
                score += 1
            
            # T√°vols√°g alap√∫ pontsz√°m - KRITIKUS None-check hozz√°adva
            if distance is not None:  # Hozz√°adott None-check
                if distance < 5:
                    score += 2
                elif distance < 15:
                    score += 1
                elif distance > 30:
                    score -= 1
                elif distance > 45:
                    score -= 2
            
            # Adatok teljess√©ge - None-safe m√≥don
            if hasattr(station, 'inventory') and station.inventory:
                inventory = station.inventory
                
                # Daily data min≈ës√©g - BIZTONS√ÅGOS ELLEN≈êRZ√âS
                daily_end = self._safe_inventory_check(inventory, 'daily', 'end')
                if daily_end and daily_end >= '2023-01-01':  # Csak akkor hasonl√≠tunk, ha nem None
                    score += 2
                elif daily_end and daily_end >= '2020-01-01':
                    score += 1
                
                # Hourly data min≈ës√©g - BIZTONS√ÅGOS ELLEN≈êRZ√âS
                hourly_end = self._safe_inventory_check(inventory, 'hourly', 'end')
                if hourly_end and hourly_end >= '2020-01-01':  # Csak akkor hasonl√≠tunk, ha nem None
                    score += 1
                
                # Recent data availability - BIZTONS√ÅGOS ELLEN≈êRZ√âS
                daily_start = self._safe_inventory_check(inventory, 'daily', 'start')
                if daily_start and daily_start <= '1990-01-01':  # Csak akkor hasonl√≠tunk, ha nem None
                    score += 1  # Historical data b√≥nusz
            
            # Elevation inform√°ci√≥
            if hasattr(station, 'elevation') and station.elevation is not None:
                score += 1
            
            # Speci√°lis √°llom√°sok b√≥nusz
            special_type = hungaromet_data.get('special')
            if special_type in ['capital', 'highest_point', 'climate_station']:
                score += 2
            elif special_type in ['major_city', 'nuclear_plant']:
                score += 1
            
            # Country match b√≥nusz
            if hasattr(station, 'country') and station.country == "HU":
                score += 1
                
        except Exception as e:
            logger.warning(f"Quality score sz√°m√≠t√°si hiba: {e}")
            score = 3  # Biztons√°gos fallback √©rt√©k
        
        return max(1, min(10, int(score)))  # Biztos√≠tjuk, hogy int legyen
    
    def _log_processing_error(self, city_name: str, error_type: str, error_message: str, processing_step: str) -> None:
        """
        Processing hib√°k napl√≥z√°sa adatb√°zisba audit trail c√©lj√°b√≥l
        
        Args:
            city_name: √ârintett v√°ros neve
            error_type: Hiba t√≠pusa
            error_message: Hiba √ºzenet
            processing_step: Processing l√©p√©s ahol a hiba t√∂rt√©nt
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT INTO processing_errors (city_name, error_type, error_message, processing_step)
                    VALUES (?, ?, ?, ?)
                ''', (city_name, error_type, error_message, processing_step))
                conn.commit()
        except sqlite3.Error as e:
            logger.error(f"Error logging hiba: {e}")
    
    def save_to_database(self, df: pd.DataFrame) -> None:
        """
        DataFrame ment√©se SQLite adatb√°zisba batch m√≥dban
        Professional database operations with transaction safety
        JAV√çTOTT: pandas NaType ‚Üí None konverzi√≥ (SQLite compatibility)
        
        Args:
            df: V√°rosadatok DataFrame
            
        Raises:
            sqlite3.Error: Adatb√°zis m≈±veleti hib√°k
        """
        logger.info("üíæ Adatok ment√©se SQLite adatb√°zisba...")
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("BEGIN TRANSACTION")
                
                # Cities t√°bla felt√∂lt√©se batch m√≥dban
                records_to_insert = []
                
                for _, row in df.iterrows():
                    try:
                        # KRITIKUS JAV√çT√ÅS: pandas NaType ‚Üí None konverzi√≥ minden mez≈ën√©l
                        def safe_value(value):
                            """Pandas NaType safe konverzi√≥ None-ra."""
                            if pd.isna(value):
                                return None
                            return value
                        
                        record = (
                            safe_value(row['city']),
                            float(row['lat']),
                            float(row['lon']),
                            safe_value(row['country']),
                            safe_value(row['country_code']),
                            int(row.get('population')) if pd.notna(row.get('population')) else None,
                            safe_value(row.get('continent')),        # JAV√çTVA
                            safe_value(row.get('admin_name')),       # JAV√çTVA  
                            safe_value(row.get('capital')),          # JAV√çTVA
                            safe_value(row.get('timezone')),         # JAV√çTVA - Ez volt a 9. param√©ter!
                            safe_value(row.get('meteostat_station_id')),     # JAV√çTVA
                            safe_value(row.get('meteostat_station_name')),   # JAV√çTVA
                            float(row.get('station_elevation')) if pd.notna(row.get('station_elevation')) else None,
                            float(row.get('station_distance')) if pd.notna(row.get('station_distance')) else None,
                            safe_value(row.get('station_inventory')),        # JAV√çTVA
                            int(row.get('hungaromet_priority')) if pd.notna(row.get('hungaromet_priority')) else None,
                            int(row.get('data_quality_score')) if pd.notna(row.get('data_quality_score')) else None,
                            safe_value(row.get('last_data_update'))          # JAV√çTVA
                        )
                        records_to_insert.append(record)
                        
                    except (ValueError, TypeError) as e:
                        logger.warning(f"Rekord conversion hiba {row['city']}: {e}")
                        self.stats['validation_errors'] += 1
                        continue
                
                # Batch insert v√©grehajt√°sa
                cursor = conn.cursor()
                cursor.executemany('''
                    INSERT INTO cities (
                        city, lat, lon, country, country_code, population,
                        continent, admin_name, capital, timezone,
                        meteostat_station_id, meteostat_station_name,
                        station_elevation, station_distance, station_inventory,
                        hungaromet_priority, data_quality_score, last_data_update
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', records_to_insert)
                
                # Metaadat ment√©se
                cursor.execute('''
                    INSERT INTO generation_metadata (
                        csv_file_path, total_cities, hungarian_cities,
                        cities_with_stations, meteostat_requests, api_errors,
                        validation_errors, processing_time_seconds, meteostat_api_key_hash
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    str(self.csv_path),
                    self.stats['total_cities'],
                    self.stats['hungarian_cities'],
                    self.stats['cities_with_stations'],
                    self.stats['meteostat_requests'],
                    self.stats['api_errors'],
                    self.stats['validation_errors'],
                    self.stats['processing_time'],
                    hash(self.meteostat_api_key)
                ))
                
                conn.execute("COMMIT")
                logger.info(f"‚úÖ Adatb√°zis sikeresen mentve: {len(records_to_insert):,} rekord")
                
        except sqlite3.Error as e:
            logger.error(f"‚ùå Adatb√°zis ment√©si hiba: {e}")
            raise
        except Exception as e:
            logger.error(f"‚ùå V√°ratlan hiba ment√©s sor√°n: {e}")
            raise
    
    def validate_database(self) -> None:
        """
        Adatb√°zis valid√°l√°sa √©s r√©szletes statisztik√°k ki√≠r√°sa
        Professional data quality assessment
        """
        logger.info("üîç Adatb√°zis valid√°l√°sa √©s min≈ës√©g ellen≈ërz√©se...")
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Alapstatisztik√°k lek√©rdez√©se
                cursor.execute("SELECT COUNT(*) FROM cities")
                total_cities = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM cities WHERE country_code = 'HU'")
                hungarian_cities = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM cities WHERE meteostat_station_id IS NOT NULL")
                cities_with_stations = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM cities WHERE country_code = 'HU' AND meteostat_station_id IS NOT NULL")
                hungarian_cities_with_stations = cursor.fetchone()[0]
                
                # Adatmin≈ës√©g statisztik√°k
                cursor.execute('''
                    SELECT AVG(data_quality_score), MIN(data_quality_score), MAX(data_quality_score)
                    FROM cities 
                    WHERE country_code = 'HU' AND data_quality_score IS NOT NULL
                ''')
                quality_stats = cursor.fetchone()
                
                # Top 10 magyar v√°ros adatmin≈ës√©g szerint
                cursor.execute('''
                    SELECT city, data_quality_score, meteostat_station_name, 
                           ROUND(station_distance, 1) as distance
                    FROM cities 
                    WHERE country_code = 'HU' AND meteostat_station_id IS NOT NULL
                    ORDER BY data_quality_score DESC, station_distance ASC
                    LIMIT 10
                ''')
                top_hungarian_cities = cursor.fetchall()
                
                # Error summary
                cursor.execute("SELECT COUNT(*) FROM processing_errors")
                total_errors = cursor.fetchone()[0]
                
                # Kontinens eloszl√°s
                cursor.execute('''
                    SELECT continent, COUNT(*) as count
                    FROM cities 
                    WHERE continent IS NOT NULL
                    GROUP BY continent
                    ORDER BY count DESC
                    LIMIT 5
                ''')
                continent_distribution = cursor.fetchall()
                
                # Success rate sz√°m√≠t√°s
                hungarian_success_rate = (hungarian_cities_with_stations / hungarian_cities * 100) if hungarian_cities > 0 else 0
                global_station_coverage = (cities_with_stations / total_cities * 100) if total_cities > 0 else 0
                
                # Eredm√©nyek megjelen√≠t√©se
                logger.info("=" * 80)
                logger.info("üèÜ ADATB√ÅZIS VALID√ÅCI√ìS EREDM√âNYEK - PROFESSIONAL REPORT")
                logger.info("=" * 80)
                logger.info(f"üìä ALAPSTATISZTIK√ÅK:")
                logger.info(f"   √ñsszes v√°ros: {total_cities:,}")
                logger.info(f"   Magyar v√°rosok: {hungarian_cities}")
                logger.info(f"   Meteorol√≥giai √°llom√°ssal rendelkez≈ë v√°rosok: {cities_with_stations:,}")
                logger.info(f"   Magyar v√°rosok √°llom√°sokkal: {hungarian_cities_with_stations}/{hungarian_cities} ({hungarian_success_rate:.1f}%)")
                logger.info("")
                logger.info(f"üåê GLOBAL COVERAGE:")
                logger.info(f"   √Ållom√°s lefedetts√©g: {global_station_coverage:.2f}%")
                logger.info("")
                logger.info(f"üîó API STATISZTIK√ÅK:")
                logger.info(f"   Meteostat API k√©r√©sek: {self.stats['meteostat_requests']}")
                logger.info(f"   API hib√°k: {self.stats['api_errors']}")
                logger.info(f"   Valid√°ci√≥s hib√°k: {self.stats['validation_errors']}")
                logger.info(f"   √ñsszes processing hiba: {total_errors}")
                logger.info(f"   Feldolgoz√°si id≈ë: {self.stats['processing_time']:.2f} m√°sodperc")
                logger.info("")
                
                if quality_stats and quality_stats[0]:
                    logger.info(f"üìà MAGYAR V√ÅROSOK ADATMIN≈êS√âG:")
                    logger.info(f"   √Åtlagos min≈ës√©g: {quality_stats[0]:.1f}/10")
                    logger.info(f"   Legalacsonyabb: {quality_stats[1]}/10")
                    logger.info(f"   Legmagasabb: {quality_stats[2]}/10")
                    logger.info("")
                
                logger.info("üèÖ TOP 10 MAGYAR V√ÅROS (adatmin≈ës√©g szerint):")
                logger.info("-" * 80)
                for i, (city, quality, station, distance) in enumerate(top_hungarian_cities, 1):
                    logger.info(f"{i:2d}. {city:.<25} {quality}/10 | {station} ({distance} km)")
                logger.info("")
                
                if continent_distribution:
                    logger.info("üåç KONTINENS ELOSZL√ÅS (Top 5):")
                    logger.info("-" * 40)
                    for continent, count in continent_distribution:
                        logger.info(f"   {continent}: {count:,} v√°ros")
                    logger.info("")
                
                logger.info("=" * 80)
                logger.info("‚úÖ ADATB√ÅZIS SIKERESEN L√âTREHOZVA √âS VALID√ÅLVA!")
                logger.info("=" * 80)
                
        except sqlite3.Error as e:
            logger.error(f"‚ùå Adatb√°zis valid√°ci√≥s hiba: {e}")
            raise
    
    def run(self) -> None:
        """
        Teljes adatb√°zis gener√°l√°si folyamat futtat√°sa
        Professional orchestration with comprehensive error handling
        
        Raises:
            Exception: Kritikus hib√°k eset√©n
        """
        start_time = time.time()
        
        try:
            logger.info("üöÄ V√°ros-adatb√°zis gener√°l√°s kezd√©se (Professional v2.1.0)...")
            logger.info("=" * 80)
            
            # 1. Adatb√°zis s√©ma l√©trehoz√°sa
            self.create_database_schema()
            
            # 2. SimpleMaps adatok bet√∂lt√©se √©s valid√°l√°sa
            df = self.load_simplemaps_data()
            
            # 3. Magyar v√°rosok kieg√©sz√≠t√©se Meteostat √°llom√°sokkal (JAV√çTOTT)
            df = self.enhance_hungarian_cities(df)
            
            # 4. Adatb√°zis ment√©se batch m√≥dban
            self.save_to_database(df)
            
            # 5. Adatb√°zis valid√°l√°sa √©s min≈ës√©g ellen≈ërz√©se
            self.validate_database()
            
            # Feldolgoz√°si id≈ë friss√≠t√©se
            self.stats['processing_time'] = time.time() - start_time
            
            logger.info("")
            logger.info("üéâ V√ÅROS-ADATB√ÅZIS GENER√ÅL√ÅS SIKERESEN BEFEJEZVE!")
            logger.info(f"‚è±Ô∏è Teljes feldolgoz√°si id≈ë: {self.stats['processing_time']:.2f} m√°sodperc")
            logger.info("=" * 80)
            
        except Exception as e:
            logger.error(f"‚ùå KRITIKUS HIBA a gener√°l√°s sor√°n: {e}")
            logger.error("üí° Ellen≈ërizd a log f√°jlokat √©s az API kulcsot!")
            raise


def main() -> int:
    """
    F≈ëprogram - parancssori futtat√°s professional error handling-gel
    
    Returns:
        Exit k√≥d (0=success, 1=error)
    """
    try:
        # K√∂rnyezeti v√°ltoz√≥k bet√∂lt√©se
        load_dotenv()
        
        # Konfigur√°ci√≥k - JAV√çTOTT el√©r√©si √∫tvonalak
        csv_path = "worldcities.csv"  # JAV√çTVA: scripts/ k√∂nyvt√°rban futtatva
        db_path = "../src/data/cities.db"  # JAV√çTVA: relat√≠v el√©r√©si √∫t
        api_key = os.getenv("METEOSTAT_API_KEY")
        
        # Input valid√°ci√≥k
        if not api_key:
            logger.error("‚ùå METEOSTAT_API_KEY k√∂rnyezeti v√°ltoz√≥ hi√°nyzik!")
            logger.error("üí° Hozz l√©tre .env f√°jlt az API kulccsal!")
            return 1
        
        if not Path(csv_path).exists():
            logger.error(f"‚ùå SimpleMaps CSV nem tal√°lhat√≥: {csv_path}")
            logger.error("üí° T√∂ltsd le a worldcities.csv f√°jlt a SimpleMaps-r√≥l!")
            logger.info(f"üîç Aktu√°lis k√∂nyvt√°r: {os.getcwd()}")
            logger.info(f"üìÅ Keresett f√°jl: {Path(csv_path).absolute()}")
            return 1
        
        # Logs k√∂nyvt√°r m√°r l√©trehozva modul szinten
        # Path("logs").mkdir(exist_ok=True)  # Elt√°vol√≠tva, mert fentebb m√°r megt√∂rt√©nt
        
        # Gener√°tor l√©trehoz√°sa √©s futtat√°sa
        populator = CityDatabasePopulator(csv_path, db_path, api_key)
        populator.run()
        
        logger.info("üéØ Program sikeresen befejezve!")
        return 0
        
    except FileNotFoundError as e:
        logger.error(f"‚ùå F√°jl nem tal√°lhat√≥: {e}")
        return 1
    except ValueError as e:
        logger.error(f"‚ùå Konfigur√°ci√≥s hiba: {e}")
        return 1
    except Exception as e:
        logger.error(f"‚ùå V√°ratlan hiba: {e}")
        logger.exception("Full stacktrace:")
        return 1


if __name__ == "__main__":
    exit(main())